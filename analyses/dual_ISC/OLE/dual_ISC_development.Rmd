---
title: "dual ISC"
output: html_document
---

```{r}
library(dplyr)
library(RNifti)

# Immutable parameters
gitdir <- "/data00/layerfMRI/Github_repo/"
bd <- paste0(gitdir,"layerfMRI/analyses/dual_ISC/")

regdatadir <- "/data00/layerfMRI/regdata/"

df <- read.csv("log_summary.csv") %>% 
  arrange(subject,session,task,run) %>% 
  select(-c(Trial,Event.Type,Time,NMov))

df

```


## Load a 4D nifti
```{r}

niifile <- paste0(regdatadir, "/sub_02/ses_01/func/task_1_run_1_4D.nii.gz")

nii <- readNifti(niifile)

dim(nii)

niimean <- apply(nii, MARGIN = c(1,2,3), mean)

image(niimean[5, , ])

```




## Automatically add rows for JU ROI and depth bins
The trick is to create new columns, and then pivot wider.
Maybe it will actually not be necessary, since the columns are automatically created during the analysis, and then they can be pivoted (if necessary)

```{r}

# df <- tibble(sub = letters[1:3])
# 
# df %>% 
#   mutate(BA1 = NA, BA2 = NA) %>% 
#   pivot_longer(cols = c(BA1,BA2), names_to = "JU", values_to = "juval") %>% 
#   mutate(bin1 = NA, bin2 = NA) %>% 
#   pivot_longer(cols = c(bin1,bin2), names_to = "bins", values_to = "binvals") %>%
#   select(-c(juval,binvals)) %>%
#   nest(poppa = c(JU,bins)) %>% 
#   unnest()



# initial df
df <- tibble(sub = 1:10)

# read the table with the names of JU ROI and remove WM regions
julabels <- read.csv("labels_juelich.csv", stringsAsFactors = F) %>% 
  mutate(name = str_replace(name,"['-/]","")) %>%    # get rid of special chars
  mutate(numba = index + 1) %>%
  filter(grepl("GM", name)) %>% 
  select(-index)


# add columns for JU ROI names
df[julabels$name] = NA
df

# pivot JU ROI names to put them in rows (and remove WM)
df <- df %>%
  pivot_longer(cols = contains("GM"), names_to="JU_name") %>% 
  select(-value)

which(julabels$name == "GM_Anterior_intraparietal_sulcus_hIP1_L")

# add columns for depth bins
nbin <- 5
# dfbins <- tibble(bin = as.character(1:nbin))
dfbins <- map_chr(1:nbin, ~ paste0("bin",.x)) %>% as.tibble() %>% rename(nbin = value)

df[dfbins$nbin] = NA


# pivot bins to put them in rows
df <- df %>% 
  pivot_longer(cols = contains("bin"), names_to="bin") %>% 
  select(-value)

```




## Extract for one movie
```{r}

df <- read.csv("log_summary.csv") %>% 
  arrange(subject,session,task,run) %>% 
  select(-c(Trial,Event.Type,Time,NMov,session))

# df <- df %>% 
#   filter(subject == 2, Title == "S1ballonD.avi", run == 1)

df <- df %>% 
  filter(subject == 2, task == 1, run == 1, Type == "M")

df

sub <- "sub_02"
ses = "01"
task = 1
run = 1

fmri <- paste0(regdatadir, "/",sub,"/ses_",ses,"/func/task_",task,"_run_",run,"_4D.nii.gz") %>% readNifti()


# read the files to create the mask to be passed to the 4D fmri matrix
JU_nii <- paste0(bd, "/data_native/", sub, "/atlas/", sub,"_atlas_task_",task,"_run_",run,".nii.gz") %>% readNifti()
D_nii <- paste0(bd, "/data_native/", sub, "/depth/", sub,"_depth_task_",task,"_run_",run,".nii.gz") %>% readNifti()
Z_nii <- paste0(bd, "/data_native/", sub, "/Zstat/", "task_",task,"_run_",run,"/thresh_zstat1.nii.gz") %>% readNifti()

zthr <- 2.3

get_Z_D_JU_vals <- function(zthr, Z_nii, D_nii, JU_nii) {
  
  # Create an index of sig voxels, i.e. whose value is > zthr
  Zthr_idx <- which(Z_nii > zthr)
  
  # Extract Z, D, JU values at the location of Zthr_idx
  Z <- Z_nii[Zthr_idx]
  D <- D_nii[Zthr_idx]
  JU <- JU_nii[Zthr_idx]
 
  # Purrr everything into a list of tibbles and retain only D,Z values 
  # inside JU ROIs
  vals <- tibble(Zthr_idx, Z, D, JU) %>%
    rename(idx = Zthr_idx) %>% 
    filter(JU > 0)

  return(vals)
}


vals <- get_Z_D_JU_vals(zthr, Z_nii, D_nii, JU_nii)

vals


fmri %>% dim()

plot(fmri[10, 100, 100, ], type = 'l' )

df

nbin <- 5
clusterSizeThr <- 50

vals %>% 
  group_by(JU) %>%                    # 1. group_by JU ROI
  mutate(nvox = n()) %>%              # 2. count numba vox in each JU ROI
  arrange(nvox, JU) %>%               # sort by ascending nvox, just to check
  filter(nvox > clusterSizeThr) %>%   # 3. remove JU with nvox < clusterSizeThr
  mutate(D_bins = findInterval(D, seq(0, 1, by=1/nbin))) %>% arrange(D_bins) %>% 
  group_by(JU,D_bins) %>% 
  filter(JU == 33, D_bins == 1)

idx <- c(10,11,12)

df %>% 
  filter(subject == 2, task == 1, run == 1)


```



## Oh madonna! I have to splat the 4D onto a 2D...
```{r}
library(abind)

a <- array(1:9, dim = c(3,3))

# equivalent of repmat
a4d <- do.call("abind", list(rep(list(a), 10), along=3) )

a4d %>% dim()

matrix(a4d,9,10)


a <- array(1:27, dim = c(3,3,3))
# equivalent of repmat
a4d <- do.call("abind", list(rep(list(a), 10), along=4) )
a4d %>% dim()
matrix(a4d, prod(dim(a4d)[1:3]), dim(a4d)[4])


fmri %>% dim()

fmrimat <- matrix(fmri, nrow = prod(dim(fmri)[1:3]), ncol = dim(fmri)[4])

fmrimat %>% dim()

pp <- fmrimat[1e6:(1e6+1000),]

pp %>% dim()

image(t(pp))
plot(pp[1,],type='l')

```




## Let's try to put these puta lists into cells
```{r}

library(tibble)
library(dplyr)
library(purrr)
library(tidyr)
options(digits = 3)

numbarows <- 8

pf <- tibble(
  sub = 1:numbarows, 
  arr = map(1:numbarows, ~ list(NA) )  # this is to create a column which is a list of lists
)


pf <- tibble(
  sub = 1:numbarows, 
  arr = map(1:numbarows, ~ rnorm(3))
)


# unwrap the lists to be able to write.csv (1)
pf %>% 
  group_by(sub) %>% 
  mutate(arroz = paste(arr))

# unwrap the lists to be able to write.csv (2)
pf %>% 
  rowwise() %>% 
  mutate_if(is.list, ~ paste(unlist(.), collapse = ','))

# there might also be a solution with unnest, see:
# https://stackoverflow.com/questions/48024266/save-a-data-frame-with-list-columns-as-csv-file
pf %>% unnest(arr) 


```






































## Design for 1 taskrun of 1 sub

### Select 1 sub/task/run
```{r}
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(RNifti)
library(tictoc)
library(ggplot2)
options(digits = 3)

# Immutable parameters
gitdir <- "/data00/layerfMRI/Github_repo/"
bd <- paste0(gitdir,"layerfMRI/analyses/dual_ISC/")
regdatadir <- "/data00/layerfMRI/regdata/"
depthdatadir <- paste0(bd, "/data_native/")


# load the logs and do some adjustment to names of columns and observations
df <- read.csv("log_summary.csv") %>% 
  arrange(subject,session,task,run) %>% 
  select(-c(Trial,Event.Type,Time,NMov)) %>% 
  mutate(sub = sprintf("sub_%02d",subject) ) %>%
  select(-subject) %>% 
  mutate(ses = sprintf("ses_%02d", session) ) %>% 
  select(-session) %>% 
  mutate(contrast = ifelse(Type == "M", "thresh_zstat1.nii.gz", "thresh_zstat2.nii.gz") ) %>% 
  select(-c(Type, total_TR, Duration) ) %>% 
  rename(muvi = Title)



# limit to one subject/run/contrast for development
nsub <- "sub_02"
nses <- "ses_01"  # because it's in the filename of the 4D file
ntask <- 1
nrun <- 1
ncontrast <- "thresh_zstat1.nii.gz"

df <- df %>% 
  filter(sub == nsub, ses == nses, task == ntask, run == nrun, contrast == ncontrast)

df
```

### Load images
And get idx as well as the corresponding JU and D.

Note that this is subject/taskrun/contrast specific!
```{r}

fmri4D <- paste0(regdatadir,"/",nsub,"/",nses,"/func/task_",ntask,"_run_",nrun,"_4D.nii.gz") %>% readNifti()
fmri2D <- matrix(fmri4D, nrow = prod(dim(fmri4D)[1:3]), ncol = dim(fmri4D)[4])

JU_nii <- paste0(depthdatadir,"/",nsub,"/atlas/",nsub,"_atlas_task_",ntask,"_run_",nrun,".nii.gz") %>% readNifti()
D_nii  <- paste0(depthdatadir,"/",nsub,"/depth/",nsub,"_depth_task_",ntask,"_run_",nrun,".nii.gz") %>% readNifti()
Z_nii  <- paste0(depthdatadir,"/",nsub, "/Zstat/", "task_",ntask,"_run_",nrun,"/thresh_zstat1.nii.gz") %>% readNifti()


```


### Get idx of >zthr voxels, group_by JU and bin
Note that this is subject/taskrun/contrast specific!
```{r}

zthr <- 2.3            # in the ISC results this will likely be a 0/1 logical
nbin <- 10              # define numba of bins
clusterSizeThr <- 200   # we don't want to consider JU ROIs with only 2 >zthr voxels


get_Z_D_JU_vals <- function(zthr, Z_nii, D_nii, JU_nii) {
  
  # Create an index of sig voxels, i.e. whose value is > zthr
  Zthr_idx <- which(Z_nii > zthr)
  
  # Extract Z, D, JU values at the location of Zthr_idx
  Z <- Z_nii[Zthr_idx]
  D <- D_nii[Zthr_idx]
  JU <- JU_nii[Zthr_idx]
 
  # Purrr everything into a list of tibbles and retain only D,Z values 
  # inside JU ROIs
  vals <- tibble(Zthr_idx, Z, D, JU) %>%
    rename(idx = Zthr_idx) %>% 
    filter(JU > 0)

  return(vals)
}

df_idx <- get_Z_D_JU_vals(zthr, Z_nii, D_nii, JU_nii)
df_idx

# for each bin in each JU ROI > clusterSizeThr, get the idx of the voxels 
df_idx <- df_idx %>% 
  group_by(JU) %>%                    # 1. group_by JU ROI
  mutate(nvox = n()) %>%              # 2. count numba vox in each JU ROI
  arrange(nvox, JU) %>%               # sort by ascending nvox, just to check
  filter(nvox > clusterSizeThr) %>%   # 3. remove JU with nvox < clusterSizeThr
  mutate(D_bins = findInterval(D, seq(0, 1, by=1/nbin))) %>% arrange(JU,D_bins) %>%  # 4. assign to bins
  group_by(JU,D_bins) %>%             # 5. group by JU and bins, to have separate rows in the end
  summarise(                          # 6. create a column where each cell has a list with the idx of sig voxels
    idx_voxels = list(idx),
    .groups = "drop"
  )

df_idx

```

# really? I need to inject the whole df_idx for each row of df?
fuck yeah!!! :O) finally I got it!
```{r}

# test here
mov <- tibble(muvi = c("muvi_1","muvi_2","muvi_3")) %>% mutate(shebang = list(df_idx))
mov %>% unnest(shebang)

# real deal here
pf <- df %>% 
  mutate(shebang = list(df_idx) ) %>% 
  unnest(shebang)

pf

```



## Prepare df to receive the mean time courses for each bin
We need to get for each muvi one mean time course for each bin of each JU ROI. We could do it by nesting lists, but it would probably be very complex and not easy to read (as well as write to csv).

The easiest way is to use a trick: we prepare for each movie nJU*nbin rows, where nJU is the numba of JU ROIs where there are sig voxels, and nbin is the number of bins. 

The magic is done by creating a new column filled with lists, and then unnesting it. This has to be done (1) for the bins and (2) for the JU ROI **in this order!** since there are nbins for each JU ROI.

Now for the really cool bit: of course there are _not_ sig voxels in all ROIs. Just after we create the extra rows in df, we will retain only those in which there are sig voxels using the info from df_idx!

```{r}

# read the table with the names of JU ROI and remove WM regions
julabels <- read.csv("labels_juelich.csv", stringsAsFactors = F) %>% 
  mutate(name = str_replace(name,"['-/]","")) %>%    # get rid of special chars
  mutate(numba = index + 1) %>%
  filter(grepl("GM", name)) %>% 
  select(-index)


df_BIG <- df %>% 
  mutate(bin = list(1:nbin)) %>% 
  unnest(bin) %>% 
  mutate(JU = list(julabels)) %>%
  unnest(JU) %>% 
  rename(JU_name = name, JU_numba = numba) %>% 
  relocate(bin, JU_numba, muvi)

# create an index of JU ROIs where there are sig voxels, to retain only the necessary
# rows in df_BIG
sig_JU <- df_idx %>% distinct(JU) %>% pull()

df_BIG <- df_BIG %>% 
  filter(JU_numba %in% sig_JU) %>% 
  arrange(JU_numba)

df_BIG

```


## Function to extract the mean TC given fmri2D, idx, start_TR and end_TR
```{r}

get_mean_tc <- function(fmri2D, idx, start_TR, end_TR) {
  
  tcs_at_idx_voxels <- fmri2D[idx, start_TR:end_TR] 
  zscore <- function(x, na.rm = T) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
  tcs_mean <- apply(tcs_at_idx_voxels, MARGIN = 2, mean) %>% zscore()

}


idx <- df_idx$idx_voxels[[1]]
start_TR <- 0
end_TR <- 100

idx_tcs <- fmri2D[idx, start_TR:end_TR]

get_mean_tc(fmri2D, idx, start_TR = 0, end_TR = 100) %>% plot(type='l')

```



```{r}
df
```

## dunno if it's correct after this point
since I don't recall what was poppa
```{r}
poppa <- df_idx
```


```{r}

idx

df %>%
  filter(contrast == "thresh_zstat1.nii.gz") %>% 
  rowwise() %>% 
  mutate(tc = get_mean_tc(fmri2D, poppa$lidx[[1]], start_TR, end_TR) %>% list() )




```





## Just to see how big this crap is
```{r}

shebang <- tibble(
  taskrun = c("task1_run1","task1_run2",
              "task2_run1","task2_run2",
              "task3_run1","task3_run2",
              "task4_run1","task4_run2")
) %>% 
  mutate(contrast = list(c("thresh_zstat1","thresh_zstat2"))) %>% unnest(contrast) %>% 
  mutate(movie = list(map_chr(1:10, ~ paste("movie_", .x))) ) %>% unnest(movie) %>% 
  mutate(JU = list(map_chr(1:5, ~ paste("BA_", .x)  ))) %>%  unnest(JU) %>% 
  mutate(bin = list(1:10)) %>% unnest(bin)

shebang

library(collapsibleTree)
collapsibleTree(shebang, c("taskrun","contrast","movie","JU","bin"), collapsed = T, zoomable = F)


```








## Garbage collector
```{r}

# Quick plot of all/mean tcs for a given bin
apply(idx_tcs, MARGIN = 2, mean) %>% plot(type='l')

zscore <- function(x, na.rm = T) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

idx_tcs %>% t() %>% as.tibble() %>%
  mutate_all(zscore) %>% 
  mutate(time = 1:nrow(.)) %>%
  pivot_longer(cols = starts_with("V"), names_to = "vox", values_to = "intensity") %>%
  arrange(vox) %>% 
  ggplot() +
    geom_line(aes(x = time, y = intensity, color = vox))



```




























