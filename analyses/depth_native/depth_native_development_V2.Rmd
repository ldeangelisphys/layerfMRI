---
title: "depth_native functions"
output: 
  html_document:
    code_folding: hide
---


## Select sub, Zthr and Zcontrast
```{r, message=F}

# All of the following will become selector widgets
SUBID = "sub_02"     # df %>% distinct(sub) to see all available sub
Zcontrast <- "thresh_zstat1"
Zthr <- 2.3
clusterSizeThr <- 100  # to build a meaningful histogram 
h_breaks <- seq(0, 1, 0.05) # set hist breaks to a fixed range

# -----------------------------------------------------------------------------

# Immutable parameters
gitdir <- "/data00/layerfMRI/Github_repo/"
bd <- paste0(gitdir,"layerfMRI/analyses/depth_native/")

library(stringr)
library(tidyr)
library(dplyr)
library(purrr)
select <- dplyr::select
library(tictoc)


julabels <- read.csv("labels_juelich.csv") %>% 
  mutate(name = str_replace(name,"['-/]","")) %>%    # get rid of special chars
  mutate(numba = index + 1) %>% 
  select(-index)

```




## Create dictionary of data from `list.files`
The magic is provided by `tidyr::separate`

```{r message=FALSE}

create_dizio_files <- function(data_native_dir = "data_native") {
  
  df <- list.files("data_native", recursive = T) %>% as.data.frame()
  names(df) <- "fname"
  
  
  df <- df %>%
    rowwise() %>%
    tidyr::separate(
      fname, c("sub","contrast","taskrun","zstat"),
      sep = "/", fill = "right", remove = FALSE
    ) %>%
    mutate(taskrun = str_extract(taskrun,"task_[1-4]\\_run_[1-2]")) %>%
    mutate(zstat = str_extract(zstat,"thresh_zstat[1-4]")) %>%
    mutate(pathname = paste0(bd,"/data_native/",fname)) %>%
    dplyr::select(-fname)
  
  return(df)
}


# ------------------------------  Code for Main -------------------------------
# df <- create_dizio_files()

```



## Load Z, D, JU and extract values for sig voxels
Load the nii for Zmaps (thresh_Zstat[1..4]), Depth and JUelich atlases, all in native space:

- Z_nii  : 8 for each contrast (Motion, Scrambled, M>S, S>M)
- D_nii  : 8, one for each taskrun
- JU_nii : 8, one for each taskrun

Then for each run/contrast
1. threshold the Z_nii to Z_thr and create a Zthr_idx of suprathreshold voxels
2. extract Z_vals, D_vals and JU_vals at the locations of Zthr_idx

```{r, message=F}
library(RNifti)

load_niis <- function(SUBID, Zcontrast) {

  # Load the Z_nii for a given contrast (8, one for each taskrun)
  Z_nii <- df %>% 
    filter(sub == SUBID, contrast == "Zstat", zstat == Zcontrast) %>% 
    select(pathname) %>% sapply(readNifti)

  # Load the D_nii (8 taskrun)
  D_nii <- df %>% 
    filter(sub == SUBID, contrast == "depth") %>% 
    select(pathname) %>% sapply(readNifti)

  # Load the JU_nii (8 taskrun)
  JU_nii <- df %>% 
    filter(sub == SUBID, contrast == "atlas") %>% 
    select(pathname) %>% sapply(readNifti)
  
  niis <- list(
    Z = Z_nii, 
    D = D_nii, 
    JU = JU_nii
  )
  
  return(niis)
}


get_idx_and_vals <- function(Z_thr, Z_nii, D_nii, JU_nii) {
  
  # Create an index of sig voxels according to Zthr
  Zthr_idx <- sapply(Z_nii, function(x) {which(x > Zthr)})
  
  # Extract Z, D, JU values at the location of Zthr_idx
  Z_vals <- mapply( function(vols,idx) vols[idx], Z_nii, Zthr_idx )
  D_vals <- mapply( function(depth,idx) depth[idx], D_nii, Zthr_idx )
  JU_vals <- mapply( function(atlas,idx) atlas[idx], JU_nii, Zthr_idx )
  
  idx_and_vals <- list(
    idx = Zthr_idx, 
    zvals = Z_vals, 
    depthvals = D_vals, 
    juelichvals = JU_vals
  )
  
  return(idx_and_vals)
}


# ------------------------------  Code for Main -------------------------------

# niis <- load_niis(SUBID, Zcontrast)
# 
# Z_nii  <- niis$Z
# D_nii  <- niis$D
# JU_nii <- niis$JU
# 
# idx_and_vals <- get_idx_and_vals(Z_thr, Z_nii, D_nii, JU_nii)
# 
# Zthr_idx <- idx_and_vals$idx  
# Z_vals   <- idx_and_vals$zvals 
# D_vals   <- idx_and_vals$depthvals
# JU_vals  <- idx_and_vals$juelichvals


```




## Hist for each Juelich region
- The (outer) Mapply loops on pairs of [jv = JU_vals, dv = D_vals] for each taskrun
- The (inner) Sapply loops on juelich regions if the numba sig voxels is > clusterSizeThr
- A final Sapply removes the juelich regions where the counts are NULL


```{r}


get_hist_stats_juelich_ROIs <- function(julabels, JU_vals, D_vals) {

  # Transform julabels to a list to use sapply
  julabels_list <- spread(julabels, key = name, value = numba) %>% as.list()
    
  # Create a list of length == numba taskruns (8), each one containing 
  # a list of counts for each region where the numba of sig voxels is > clusterSizeThr
  tot <- mapply(function(jv, dv) {
    
    taskrun_count <- sapply(julabels_list, function(ROInumba) {
      
      idxROI <- which(jv == ROInumba)
        
      if (length(idxROI) > clusterSizeThr) {
        hcounts <- hist(dv[idxROI], breaks = h_breaks, plot = F)$counts
      }
    })
    
    taskrun_count <- taskrun_count[!sapply(taskrun_count,is.null)]
    
  }, JU_vals, D_vals) %>% purrr::flatten()  # remove the outer list layer (i.e. taskrun)
  
  
  
  # determine unique sig ROI names
  activeROIs <- tot %>% names() %>% unique()
  
  # group by ROI
  grouped <- map(activeROIs, ~ reduce(tot[names(tot) == .x], rbind) ) %>% setNames(activeROIs)
  
  # (1) remove ROIs where a sig result occurs only in one run
  grouped <- grouped[!sapply(grouped,function(x) is.null(dim(x)) ) ]
  
  # (2) remove ROIs where a sig result occurs in less than 6/8 runs
  min_numba_run_where_sig = 6
  grouped <- grouped[!sapply(grouped,function(x) dim(x)[1] < min_numba_run_where_sig)]
  
  
  # transform to probabilities, i.e. divide the counts in each row by the sum across columns
  grouped <- lapply(grouped, function(x) x/apply(x, MARGIN = 1, sum))

  # # just checking that the sum of probabilities gives 1
  # # (i.e. to check that I summed across the right margin)
  # lapply(grouped, function(x) apply(x, MARGIN = 1, sum)) %>% print()

    
  # calculate mean p for each depth across taskrun, i.e. across rows
  MUs  <- lapply(grouped, function(x) apply(x, MARGIN = 2, mean)) %>% as.data.frame()
  
  # calculate standard error of p across depth
  sterr <- function(x) {sd(x)/sqrt(length(x))}
  ERRs <- lapply(grouped, function(x) apply(x, MARGIN = 2, sterr)) %>% as.data.frame()
  
  hist_stats = list(
    means = MUs,
    error = ERRs
  )
  
  return(hist_stats)
}


# ------------------------------  Code for Main -------------------------------

# hist_stats <- get_hist_stats_juelich_ROIs(julabels, JU_vals, D_vals)


```


## Main function to get contrast-specific results
This uses all the functions created above, and returns the mean + sterr of counts
across taskrun for a specific contrast
```{r}

# Main function, to be run for each contrast
get_contrast_specific_results <- function(SUBID, Zcontrast) {
  
  # Load Z, D, JU niftis (24)
  niis <- load_niis(SUBID, Zcontrast)
  
  Z_nii  <- niis$Z
  D_nii  <- niis$D
  JU_nii <- niis$JU
  
  
  # Extract values for sig voxels in Zstat, Depth and JUelich native maps
  idx_and_vals <- get_idx_and_vals(Z_thr, Z_nii, D_nii, JU_nii)
  
  Zthr_idx <- idx_and_vals$idx  
  Z_vals   <- idx_and_vals$zvals 
  D_vals   <- idx_and_vals$depthvals
  JU_vals  <- idx_and_vals$juelichvals
  
  
  # (1) Estimate the distribution of sig voxels at different depths for each ROI in the juelich atlas.
  # (2) Exclude ROIs where the numba of sig voxels is < clusterSizeThr in less than 6/8 runs
  # (3) Retain mean and standard error across runs
  hist_stats <- get_hist_stats_juelich_ROIs(julabels, JU_vals, D_vals)
  
  return(hist_stats)
  
}

```



## Main process
```{r}

# Create dictionary of data from list.files()
df <- create_dizio_files()

Motion_results <- get_contrast_specific_results(SUBID = "sub_02", Zcontrast = "thresh_zstat1")

Scrambled_results <- get_contrast_specific_results(SUBID = "sub_02", Zcontrast = "thresh_zstat2")

M_means <- Motion_results$means
M_error <- Motion_results$error

S_means <- Scrambled_results$means
S_error <- Scrambled_results$error

```




## Plot M! (this has to go above the main process as a function)
Great info about plotting errorbars [here](http://www.sthda.com/english/wiki/ggplot2-error-bars-quick-start-guide-r-software-and-data-visualization)
```{r}

library(ggplot2)

M_means$depth <- 1:nrow(M_means)/nrow(M_means)
M_error$depth <- 1:nrow(M_error)/nrow(M_error)

M_means_LONG <- M_means %>% 
  gather(contains("GM"), key = "ROI", value = "density")

M_error_LONG <- M_error %>% 
  gather(contains("GM"), key = "ROI", value = "error")

M <- inner_join(M_means_LONG, M_error_LONG, by = c("depth", "ROI"))


M %>% 
  ggplot(aes(x = depth, y = density, fill = depth)) +
  geom_bar(stat = "identity", width = 0.05) + 
  scale_fill_viridis_c() +
  ylim(0,0.15) +
  facet_wrap( ~ ROI) +
  geom_linerange(aes(ymin = density - error, ymax = density + error))

```



# Plot S
```{r}
library(ggplot2)

S_means$depth <- 1:nrow(S_means)/nrow(S_means)
S_error$depth <- 1:nrow(S_error)/nrow(S_error)

S_means_LONG <- S_means %>% 
  gather(contains("GM"), key = "ROI", value = "density")

S_error_LONG <- S_error %>% 
  gather(contains("GM"), key = "ROI", value = "error")

S <- inner_join(S_means_LONG, S_error_LONG, by = c("depth", "ROI"))


S %>% 
  ggplot(aes(x = depth, y = density, fill = depth)) +
  geom_bar(stat = "identity", width = 0.05) + 
  scale_fill_viridis_c() +
  ylim(0,0.15) +
  facet_wrap( ~ ROI) +
  geom_linerange(aes(ymin = density - error, ymax = density + error))




```





## Plot it! (OLE)
```{r eval=FALSE, include=FALSE}

library(ggplot2)

# add one colum showing the depth
final_counts$depth <- 1:nrow(final_counts)/nrow(final_counts) 

final_counts %>% 
  gather(contains("GM"), key = "ROI", value = "density") %>% 
  ggplot(aes(x = depth, y = density, fill = depth)) +
  geom_bar(stat = "identity", width = 0.05) +
  scale_fill_viridis_c() +
  ylim(0,0.15) +
  facet_wrap( ~ ROI)
  


final_counts %>% 
  gather(contains("GM"), key = "ROI", value = "density") %>% 
  ggplot(aes(x = depth, y = density, fill = depth)) +
  geom_bar(stat = "identity", width = 0.05) +
  geom_smooth(se = F) +
  scale_fill_viridis_c() +
  ylim(0,0.15) +
  facet_wrap( ~ ROI)



```




## Garbage

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}


N = 10

tot <- list(
  A = rnorm(N), A = rnorm(N),
  A = rnorm(N), A = rnorm(N),
  A = rnorm(N), A = rnorm(N),
  B = rnorm(N), B = rnorm(N),
  B = rnorm(N), B = rnorm(N),
  B = rnorm(N), B = rnorm(N),
  C = rnorm(N),
  C = rnorm(N)
)


# determine unique sig ROI names
activeROIs <- tot %>% names() %>% unique()

# group by ROI
grouped <- map(activeROIs, ~ reduce(tot[names(tot) == .x], rbind) ) %>% setNames(activeROIs)

# remove ROIs where a sig result occurs in less than 6/8 runs
min_numba_run_where_sig = 6
grouped <- grouped[!sapply(grouped,function(x) dim(x)[1] < min_numba_run_where_sig)]
grouped

sterr <- function(x) {sd(x)/sqrt(length(x))}

MUs  <- lapply(grouped, function(x) apply(x, MARGIN = 2, mean)) %>% as.data.frame()
ERRs <- lapply(grouped, function(x) apply(x, MARGIN = 2, sterr)) %>% as.data.frame()


```





















```{r, echo=FALSE, include=F}

# -------------------------  Garbage collector  -------------------------------

# ju_ROI_idx <- ju_ROI_idx[lapply(ju_ROI_idx,length) > clusterSizeThr]

```




```{r, echo=FALSE, include=F}

# # How mapply works

# # mapply(function(x,y))
# 
# idx = list(
#   c(1,2,3,4),
#   c(4,5,6,7)
# )
# 
# vols = list(
#   array(11:19, dim = c(3,3)),
#   array(21:29, dim = c(3,3))
# )
# 
# 
# list(
#   val_1 = vols[[1]][idx[[1]]],
#   val_2 = vols[[2]][idx[[2]]]
# )
# 
# 
# mapply(
#   function(x,y) y[x], idx, vols
# ) %>% t()




```


```{r, message=F, include=F}


```










