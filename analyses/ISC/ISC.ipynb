{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiak.isc import isc,bootstrap_isc,compute_summary_statistic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.image import index_img,concat_imgs,resample_to_img,smooth_img,math_img\n",
    "from nilearn.masking import apply_mask,unmask\n",
    "from nilearn import plotting as niplt\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import mode as statmode\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.ndimage import gaussian_filter1d, gaussian_filter\n",
    "from skimage.measure import label as dolabel\n",
    "from skimage.measure import regionprops\n",
    "from scipy.stats import ttest_1samp,ttest_ind\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "def find_fmri_duration(dataf):\n",
    "    \n",
    "    l = []\n",
    "    for i,row in dataf.iterrows():\n",
    "        this_l = nib.load(row.fmri).shape[-1]\n",
    "        if this_l < 50:\n",
    "            print(row.fmri)\n",
    "        l.append(this_l)\n",
    "        \n",
    "    l = np.array(l)\n",
    "    if len(np.unique(l)) > 1:\n",
    "        print('WTF ' + 50*'-')\n",
    "    \n",
    "    return l[0]\n",
    "\n",
    "def export_results(iscstat,c,met,t,fld_out,logsumm):\n",
    "\n",
    "    if met == 'boot':\n",
    "        STAT = 'm'\n",
    "    elif met == 't-test':\n",
    "        STAT = 't'\n",
    "\n",
    "    unthres = unmask(iscstat[c][met][STAT],av_mask_img)\n",
    "\n",
    "    if t == 'uncorrected':\n",
    "        thres_m = unmask(iscstat[c][met][STAT] * (iscstat[c][met]['p']< p_thres[t]),av_mask_img)\n",
    "    elif t == 'FDR':\n",
    "        isc_pmask,isc_pcorr = fdrcorrection(iscstat[c][met]['p'], p_thres[t])\n",
    "        thres_m = unmask(iscstat[c][met][STAT] * isc_pmask, av_mask_img)\n",
    "\n",
    "    thres_mc, cl = filter_clusters(thres_m,c_thres[t])\n",
    "    thres_mc_bin = math_img('im > 0',im=thres_mc)\n",
    "\n",
    "\n",
    "    ## Save Maps\n",
    "    # Untresholded\n",
    "#     fout = fld_out + '{}_isc_{}.nii.gz'.format(isc_type,c)\n",
    "#     nib.save(unthres, fout)\n",
    "    # Thresholded\n",
    "    fout = fld_out + '{}ISC_{}_{}_{}_p{}_k{:02d}.nii.gz'.format(isc_type,c,met,t,str(p_thres[t])[2:],c_thres[t])\n",
    "    nib.save(thres_mc, fout)\n",
    "    # Thresholded binary\n",
    "    fout = fout.replace('.nii.gz','_bin.nii.gz')\n",
    "    nib.save(thres_mc_bin, fout)\n",
    "\n",
    "    # Figure\n",
    "    fig,ax = plt.subplots(figsize = (9,3))\n",
    "    niplt.plot_glass_brain(thres_mc, figure=fig,axes=ax,colorbar = True)\n",
    "    ax.set_title(r'{} ISC - {} correction ($\\alpha = {}$, $\\kappa = {}$)'.format(isc_type,t,p_thres[t],c_thres[t]))\n",
    "\n",
    "    fout = fld_out + '{}ISC_{}_{}_{}_p{}_k{:02d}.pdf'.format(isc_type,c,met,t,str(p_thres[t])[2:],c_thres[t])\n",
    "\n",
    "    plt.savefig(fout)\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "    # Some logs\n",
    "    included_subjects = logsumm.sort_values('subject')['subject'].unique()\n",
    "    np.savetxt(fld_out + 'included_subjects.txt', included_subjects)\n",
    "\n",
    "    included_movies = logsumm.sort_values('Title')['Title'].unique()\n",
    "    np.savetxt(fld_out + 'included_movies.txt', included_movies, fmt = '%s')\n",
    "\n",
    "    return thres_mc\n",
    "\n",
    "\n",
    "def filter_clusters(thresholded_image,cluster_threshold):\n",
    "\n",
    "    imgdata = np.nan_to_num(thresholded_image.get_fdata(),0)\n",
    "    labeled = dolabel(imgdata != 0, background=0, connectivity = 2)\n",
    "    labprops = regionprops(labeled)\n",
    "\n",
    "    clusters = []\n",
    "    for c in labprops:\n",
    "        if c.area < cluster_threshold:\n",
    "            labeled[labeled == c.label] = 0\n",
    "        else:\n",
    "            clusters.append([c.label,c.area])\n",
    "        \n",
    "    clusters = np.array(clusters)\n",
    "    \n",
    "    filtered_data = imgdata*(labeled > 0)\n",
    "    filtered_image = nib.Nifti2Image(filtered_data,header=thresholded_image.header,affine=thresholded_image.affine)\n",
    "    \n",
    "    return filtered_image,clusters\n",
    "\n",
    "def do_RM_Ftest(iscdata):\n",
    "    \n",
    "    n_sub,n_vox = np.shape(iscdata['M'])\n",
    "\n",
    "    F = np.zeros(n_vox)\n",
    "    pF = np.zeros_like(F)\n",
    "\n",
    "    for nv in range(n_vox):\n",
    "        df = pd.DataFrame()\n",
    "        for c in iscdata:\n",
    "            vox_data = iscdata[c][:,nv]\n",
    "\n",
    "            this_df = (pd\n",
    "               .DataFrame(np.array([np.arange(n_sub),vox_data]).T,columns=['sub_id','z'])\n",
    "               .assign(cond = c)\n",
    "               .assign(sub_id = lambda d : d['sub_id'].astype(int))\n",
    "              )\n",
    "\n",
    "            df  = df.append(this_df)\n",
    "\n",
    "        aovrm = AnovaRM(df,'z', 'sub_id', within=['cond'])\n",
    "        res = aovrm.fit()\n",
    "\n",
    "        F[nv] = res.anova_table['F Value']\n",
    "        pF[nv] = res.anova_table['Pr > F']\n",
    "\n",
    "        print('{:07d} out of {:07d} done...'.format(nv,n_vox), end='\\r', flush=True)\n",
    "\n",
    "            \n",
    "    return F,pF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "froot = '/data00/layerfMRI/'\n",
    "isc_fld = froot + 'analyses/ISC/'\n",
    "av_mask_img = isc_fld + 'masks/average_mask_mni.nii.gz'\n",
    "Nvox = int(np.sum(apply_mask(av_mask_img,av_mask_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsumm = (pd\n",
    "           .read_csv(froot+ 'logs/log_summary.csv')\n",
    "           .assign(fmri = lambda d:\n",
    "                   froot + \n",
    "                   'regdata/sub_' + d['subject'].apply(lambda n: '{:02d}'.format(n)) +\n",
    "                   '/ses_' + d['session'].apply(lambda n: '{:02d}'.format(n)) +\n",
    "                   '/func/task_' + d['task'].apply(lambda n: '{:01d}'.format(n)) +\n",
    "                   '_run_' + d['run'].apply(lambda n: '{:01d}'.format(n)) +\n",
    "                   '_4D_MNI.nii.gz'\n",
    "                  )\n",
    "           .assign(fmri_missing = lambda d : d['fmri'].apply(lambda s: os.path.isfile(s) != True))\n",
    "           \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "froot+ 'logs/log_summary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IGNORE SUBJECT 8\n",
    "logsumm = logsumm.loc[lambda d : d['subject'] != 8]\n",
    "\n",
    "movies = {}\n",
    "for m,df in logsumm.groupby('Type'):\n",
    "    movies[m] = list(df['Title'].unique())\n",
    "    \n",
    "Nsub = logsumm['subject'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 6 # mm\n",
    "if not os.path.isdir(isc_fld + f'isc_preloaded_input_{smoothing}mm/'):\n",
    "    os.makedirs(isc_fld + f'isc_preloaded_input_{smoothing}mm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data_mov = {}\n",
    "data_mov_run = {}\n",
    "\n",
    "for c in ['M','S']:\n",
    "    data_mov[c] = {}\n",
    "    data_mov_run[c] = {}\n",
    "\n",
    "\n",
    "    for im,movfile in enumerate(movies[c]):\n",
    "\n",
    "        mov = movfile.split('.')[0]\n",
    "        data_mov_run[c][mov] = {}\n",
    "\n",
    "        for run,rdf in logsumm.loc[lambda d : d['Title'] == movfile].groupby('run'):\n",
    "\n",
    "            fpickle = isc_fld + f'isc_preloaded_input_{smoothing}mm/{c}_{mov}_run{run}.pickle'\n",
    "            if os.path.isfile(fpickle):\n",
    "                with open(fpickle, 'rb') as fid:\n",
    "                    data_mov_run[c][mov][run] = pickle.load(fid)  \n",
    "                print('{} loaded successfully'.format(fpickle))\n",
    "\n",
    "            else:\n",
    "        \n",
    "                if rdf['Duration'].nunique() == 1:\n",
    "                    lmovie = rdf['Duration'].iloc[0]\n",
    "                else:\n",
    "                    print('Multiple values found for the movie duration')\n",
    "                    if rdf['ExpectedDuration'].nunique() == 1:\n",
    "                        print('Picked the expected duration of the movie')\n",
    "                        lmovie = rdf['ExpectedDuration'].iloc[0]\n",
    "                    else:                        \n",
    "                        print('Also the exnpected duration contains more than one value. Picking the minimum')\n",
    "                        print(rdf['ExpectedDuration'].values)\n",
    "                        lmovie = np.min(rdf['ExpectedDuration'].values)\n",
    "                        print(lmovie)\n",
    "                        \n",
    "                print('Reading movie {} ({} frames)'.format(mov,lmovie))\n",
    "                \n",
    "                ## Check that start_TR + lmovie is not bigger than the niftis\n",
    "                l_fmri = find_fmri_duration(rdf)\n",
    "                start_TR_max = rdf.start_TR.max()\n",
    "                if l_fmri < start_TR_max + lmovie:\n",
    "                    print('Warning! Some movie size exceeds the number of recorded volumes')\n",
    "                    lmovie = l_fmri - start_TR_max\n",
    "                    print('length of the movie has been decreased to {}'.format(lmovie))                \n",
    "                \n",
    "\n",
    "                try:\n",
    "                    data_mov_run[c][mov][run] = np.zeros((lmovie,Nvox,Nsub))\n",
    "\n",
    "                    for i,row in rdf.sort_values('subject').reset_index().iterrows():\n",
    "\n",
    "                        # Read data\n",
    "                        st = time.time()\n",
    "                        subjdata = apply_mask(\n",
    "#                             row.fmri,\n",
    "                                smooth_img(row.fmri,6),\n",
    "                            av_mask_img\n",
    "                        )[row.start_TR:row.start_TR+lmovie,:]        \n",
    "\n",
    "                        # Standardize data\n",
    "                        avdata = np.average(subjdata, axis = 0)\n",
    "                        stdata = np.std(subjdata, axis = 0)\n",
    "                        subjdata = (subjdata - avdata[None,:])/stdata[None,:]\n",
    "                        subjdata[np.isnan(subjdata)] = 0\n",
    "                        en = time.time()\n",
    "                        print('Subject {} processed in {:.01f} s'.format(row.subject,en-st))\n",
    "\n",
    "                        # Place it in the right spot in of the array\n",
    "                        data_mov_run[c][mov][run][:,:,i] = subjdata\n",
    "\n",
    "                    # Save it in a dedicated folder\n",
    "                    with open(fpickle, 'wb') as fid:\n",
    "                        pickle.dump(data_mov_run[c][mov][run], fid, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                except:\n",
    "                    print('Some error occurred at condition {} movie {} run {} for subject {}...'.format(c,mov,run,row.subject))\n",
    "                    print('Skipping this whole run')\n",
    "\n",
    "\n",
    "        # After looping through the runs I can concatenate them into an array\n",
    "        data_mov[c][mov] = np.concatenate([data_mov_run[c][mov][run] for run in data_mov_run[c][mov]], axis = 0)\n",
    "        print('Movie {} completed [{:02d}/{:02d}]'.format(mov,im+1,len(movies[c])))\n",
    "\n",
    "    data[c] = np.concatenate([data_mov[c][mov] for mov in data_mov[c]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mov in data_mov[c]:\n",
    "    print(mov,data_mov[c][mov].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_type = 'loo' ## 'loo' or 'pair'\n",
    "dopair = (isc_type == 'pair')\n",
    "\n",
    "# fld_out = isc_fld + '{}_isc_{}mm/'.format(isc_type,smoothing)\n",
    "fld_out = '/data00/layerfMRI/Github_repo/layerfMRI/analyses/dual_ISC/4figures/fig_2_results_ISC1/'\n",
    "if not os.path.isdir(fld_out):\n",
    "    os.makedirs(fld_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscdata = {}\n",
    "\n",
    "for c in ['M','S']:\n",
    "\n",
    "    iscdata[c] = isc(data[c], pairwise=dopair)\n",
    "    iscdata[c][np.isnan(iscdata[c])] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['M','S']:\n",
    "    iscstat[c] = {'boot':{},'t-test':{}}\n",
    "    \n",
    "    iscstat[c]['boot']['m'],iscstat[c]['boot']['ci'],iscstat[c]['boot']['p'],iscstat[c]['boot']['d'] = bootstrap_isc(iscdata[c], n_bootstraps=5000, pairwise=dopair,summary_statistic='median')\n",
    "    iscstat[c]['t-test']['t'],iscstat[c]['t-test']['p'] = ttest_1samp(iscdata[c],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Measure F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 'M-S'\n",
    "# iscstat[c] = {'rep-F'}\n",
    "# n_sub,n_vox = np.shape(iscdata['M'])\n",
    "\n",
    "# iscstat[c]['repF']['m'], iscstat[c]['repF']['p'] = do_RM_Ftest(iscdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_thres = {'uncorrected':0.001}#,'FDR':0.05}\n",
    "c_thres = {'uncorrected':50}#,'FDR':20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_map = {}\n",
    "for c in iscstat:\n",
    "    thres_map[c] = {}\n",
    "    for met in iscstat[c]:\n",
    "        thres_map[c][met] = {}\n",
    "        for t in p_thres:\n",
    "            thres_map[c][met][t] = export_results(iscstat,c,met,t,fld_out,logsumm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OR map\n",
    "t = 'uncorrected'\n",
    "\n",
    "for met in ['boot','t-test']:\n",
    "\n",
    "    M_OR_S = math_img('(im1>0) + (im2>0)',im1 = thres_map['M'][met][t], im2 = thres_map['S'][met][t])\n",
    "\n",
    "    # Thresholded binary\n",
    "    fout = fld_out + '{}ISC_{}_{}_{}_p{}_k{:02d}_bin.nii.gz'.format(isc_type,'M_OR_S',met,t,str(p_thres[t])[2:],c_thres[t])\n",
    "    nib.save(M_OR_S, fout)\n",
    "\n",
    "    # Figure\n",
    "    fig,ax = plt.subplots(figsize = (9,3))\n",
    "    niplt.plot_glass_brain(M_OR_S, figure=fig,axes=ax,colorbar = True)\n",
    "    ax.set_title(r'{} ISC - {} correction ($\\alpha = {}$, $\\kappa = {}$)'.format(isc_type,t,p_thres[t],c_thres[t]))\n",
    "\n",
    "    fout = fld_out + '{}ISC_{}_{}_{}_p{}_k{:02d}_bin.pdf'.format(isc_type,'M_OR_S',met,t,str(p_thres[t])[2:],c_thres[t])\n",
    "\n",
    "    plt.savefig(fout)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiak",
   "language": "python",
   "name": "brainiak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
